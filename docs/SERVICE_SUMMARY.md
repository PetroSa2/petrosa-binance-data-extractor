# Petrosa Binance Data Extractor - Service Summary

## ğŸ¯ Overview

The Petrosa Binance Data Extractor is a comprehensive, production-ready historical data extraction system designed to collect, process, and store market data from Binance cryptocurrency exchange. It supports extraction of klines (candlesticks), funding rates, and trades data with automatic gap detection and filling capabilities.

## ğŸ—ï¸ Architecture

### Core Components

1. **Extraction Jobs** (`jobs/`)
   - `extract_klines_production.py`: Production-ready klines extractor for Kubernetes
   - `extract_klines_gap_filler.py`: Gap detection and filling job
   - `extract_funding.py`: Funding rates extraction
   - `extract_trades.py`: Trades data extraction

2. **API Fetchers** (`fetchers/`)
   - `client.py`: Base Binance API client with rate limiting
   - `klines.py`: Klines data fetcher
   - `funding.py`: Funding rates fetcher
   - `trades.py`: Trades data fetcher

3. **Database Adapters** (`db/`)
   - `base_adapter.py`: Abstract base class for database operations
   - `mongodb_adapter.py`: MongoDB implementation
   - `mysql_adapter.py`: MySQL implementation

4. **Data Models** (`models/`)
   - `base.py`: Base model with common fields
   - `kline.py`: Kline (candlestick) data model
   - `funding_rate.py`: Funding rate model
   - `trade.py`: Trade data model

5. **Utilities** (`utils/`)
   - `logger.py`: Structured logging configuration
   - `time_utils.py`: Time handling utilities
   - `telemetry.py`: OpenTelemetry integration

### Data Flow

```
Binance API â†’ Fetchers â†’ Data Models â†’ Database Adapters â†’ Storage
```

## ğŸ“ Project Structure

```
petrosa-binance-data-extractor/
â”œâ”€â”€ jobs/                   # Data extraction jobs
â”‚   â”œâ”€â”€ extract_klines_production.py  # Production klines extractor
â”‚   â”œâ”€â”€ extract_klines_gap_filler.py  # Gap detection and filling
â”‚   â”œâ”€â”€ extract_klines.py            # Manual klines extraction
â”‚   â”œâ”€â”€ extract_funding.py           # Funding rates extraction
â”‚   â””â”€â”€ extract_trades.py            # Trades extraction
â”œâ”€â”€ fetchers/              # API clients
â”‚   â”œâ”€â”€ client.py          # Base Binance client
â”‚   â”œâ”€â”€ klines.py          # Klines fetcher
â”‚   â”œâ”€â”€ funding.py         # Funding rates fetcher
â”‚   â””â”€â”€ trades.py          # Trades fetcher
â”œâ”€â”€ models/                # Data models
â”‚   â”œâ”€â”€ base.py            # Base model
â”‚   â”œâ”€â”€ kline.py           # Kline data model
â”‚   â”œâ”€â”€ funding_rate.py    # Funding rate model
â”‚   â””â”€â”€ trade.py           # Trade model
â”œâ”€â”€ db/                    # Database adapters
â”‚   â”œâ”€â”€ base_adapter.py    # Base adapter interface
â”‚   â”œâ”€â”€ mongodb_adapter.py # MongoDB adapter
â”‚   â””â”€â”€ mysql_adapter.py   # MySQL adapter
â”œâ”€â”€ utils/                 # Utilities
â”‚   â”œâ”€â”€ logger.py          # Logging configuration
â”‚   â”œâ”€â”€ time_utils.py      # Time utilities
â”‚   â””â”€â”€ telemetry.py       # OpenTelemetry setup
â”œâ”€â”€ socket_client/         # WebSocket client (separate component)
â”œâ”€â”€ tests/                 # Test suite
â”‚   â”œâ”€â”€ unit/              # Unit tests
â”‚   â”œâ”€â”€ integration/       # Integration tests
â”‚   â””â”€â”€ e2e/               # End-to-end tests
â”œâ”€â”€ k8s/                   # Kubernetes manifests
â”‚   â”œâ”€â”€ cronjobs.yaml      # Scheduled extraction jobs
â”‚   â”œâ”€â”€ configmap.yaml     # Configuration
â”‚   â””â”€â”€ secrets.yaml       # Database credentials
â”œâ”€â”€ scripts/               # Automation scripts
â”‚   â””â”€â”€ run_pipeline.py    # Pipeline orchestration
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ requirements.txt       # Production dependencies
â”œâ”€â”€ requirements-dev.txt   # Development dependencies
â”œâ”€â”€ pyproject.toml        # Project configuration
â”œâ”€â”€ pytest.ini           # Test configuration
â”œâ”€â”€ ruff.toml            # Linting configuration
â”œâ”€â”€ Dockerfile           # Multi-stage Docker build
â”œâ”€â”€ otel_init.py         # OpenTelemetry setup
â”œâ”€â”€ constants.py         # Configuration constants
â”œâ”€â”€ Makefile             # Development commands
â”œâ”€â”€ .cursorrules         # Cursor AI rules
â””â”€â”€ README.md            # Project documentation
```

## ğŸ”§ Key Features

### Historical Data Extraction
- **Multiple Data Types**: Klines, funding rates, trades
- **Configurable Intervals**: 1m to 1M timeframes
- **High Performance**: Parallel processing with configurable workers
- **Gap Detection**: Automatic detection of missing data periods

### Database Support
- **Multiple Databases**: MongoDB, MySQL, PostgreSQL
- **Batch Processing**: Efficient bulk insert operations
- **Connection Pooling**: Optimized database connections
- **Data Validation**: Pydantic-based validation before storage

### Production Ready
- **Kubernetes Native**: CronJobs for scheduled extraction
- **Error Handling**: Robust error handling and retry logic
- **Monitoring**: OpenTelemetry integration for observability
- **Security**: Secure credential management via Kubernetes secrets

## ğŸš€ Deployment

### Local Development
```bash
# Setup environment
make setup

# Run extraction jobs
python -m jobs.extract_klines_production --period 15m
python -m jobs.extract_funding
python -m jobs.extract_trades

# Run tests
make test

# Run complete pipeline
make pipeline
```

### Docker
```bash
# Build image
make build

# Run container
make run-docker

# Test container
make container
```

### Kubernetes
```bash
# Deploy to Kubernetes
make deploy

# Check status
make k8s-status

# View logs
make k8s-logs
```

## âš™ï¸ Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `BINANCE_API_URL` | `https://api.binance.com` | Binance REST API URL |
| `BINANCE_FUTURES_API_URL` | `https://fapi.binance.com` | Binance Futures API URL |
| `DEFAULT_SYMBOLS` | `BTCUSDT,ETHUSDT,BNBUSDT` | Default trading symbols |
| `MONGODB_URI` | `mongodb://localhost:27017` | MongoDB connection URI |
| `MYSQL_URI` | `mysql://user:pass@localhost:3306` | MySQL connection URI |
| `POSTGRESQL_URI` | `postgresql://user:pass@localhost:5432` | PostgreSQL connection URI |
| `DB_ADAPTER` | `mysql` | Default database adapter |
| `DB_BATCH_SIZE` | `1000` | Database batch size for writes |
| `LOG_LEVEL` | `INFO` | Logging level |
| `MAX_WORKERS` | `4` | Maximum parallel workers |
| `LOOKBACK_HOURS` | `24` | Default lookback period in hours |

### Supported Data Types

- **Klines (Candlesticks)**: OHLCV data for various time intervals
- **Funding Rates**: Perpetual contract funding rates
- **Trades**: Individual trade data
- **Gap Filling**: Automatic detection and filling of missing data

### Supported Intervals

- **1m, 3m, 5m, 15m, 30m**: Short-term intervals
- **1h, 2h, 4h, 6h, 8h, 12h**: Medium-term intervals
- **1d, 3d**: Long-term intervals
- **1w, 1M**: Weekly and monthly intervals

## ğŸ“Š Monitoring

### Health Endpoints
- `GET /healthz` - Liveness probe
- `GET /ready` - Readiness probe
- `GET /metrics` - Prometheus metrics
- `GET /` - Service information

### Metrics
- **Extraction Metrics**: Records processed, errors, gaps found
- **Performance Metrics**: Memory usage, CPU usage, processing time
- **Database Metrics**: Connection status, query performance
- **API Metrics**: Request success rate, response times

### Logging
Structured JSON logging with configurable levels:
```json
{
  "timestamp": "2024-01-01T00:00:00.000Z",
  "level": "INFO",
  "logger": "jobs.extract_klines_production",
  "message": "Starting klines extraction",
  "symbols": ["BTCUSDT"],
  "period": "15m",
  "start_date": "2024-01-01T00:00:00Z"
}
```

## ğŸ§ª Testing

### Test Coverage
- **Data models**: 100%
- **Database adapters**: 95%
- **Fetchers**: 90%
- **Jobs**: 85%

### Test Categories
- **Unit Tests**: Individual component testing
- **Integration Tests**: Component interaction testing
- **End-to-End Tests**: Full system testing

### Running Tests
```bash
# Run all tests
make test

# Run specific test categories
make unit
make integration
make e2e

# Run with coverage
make coverage
```

## ğŸ”’ Security

### Security Features
- **Non-root Containers**: All containers run as non-root user
- **Secret Management**: Kubernetes secrets for sensitive data
- **RBAC**: Role-based access control for Kubernetes resources
- **Dependency Scanning**: Automated vulnerability scanning
- **Code Security**: Static analysis with bandit

### Best Practices
- API keys stored in Kubernetes secrets
- Minimal container privileges
- Regular dependency updates
- Security scanning in CI/CD

## ğŸ³ Docker

### Multi-stage Build
- **Builder Stage**: Install dependencies and build
- **Production Stage**: Minimal runtime image
- **Development Stage**: Includes development tools
- **Testing Stage**: Includes test dependencies

### Image Variants
- `petrosa-binance-data-extractor:latest` - Production image
- `petrosa-binance-data-extractor:alpine` - Lightweight Alpine image
- `petrosa-binance-data-extractor:dev` - Development image

## â˜¸ï¸ Kubernetes

### Deployment Features
- **CronJobs**: Scheduled data extraction jobs
- **ConfigMaps**: Configuration management
- **Secrets**: Database credentials and API keys
- **Resource Limits**: Memory and CPU constraints
- **Security**: Non-root user and read-only filesystem

### Configuration Management
- **ConfigMap**: `petrosa-binance-data-extractor-config`
- **Secrets**: Uses existing `petrosa-sensitive-credentials`

## ğŸ”„ CI/CD

### Pipeline Stages
1. **Setup**: Environment and dependencies
2. **Lint**: Code quality checks (flake8, black, ruff, mypy)
3. **Test**: Unit tests with coverage
4. **Security**: Vulnerability scanning with Trivy
5. **Build**: Docker image building
6. **Container**: Container testing
7. **Deploy**: Kubernetes deployment

### GitHub Actions
- Automated testing and building
- Docker image publishing
- Kubernetes deployment
- Security scanning

## ğŸ“š API Reference

### Extraction Jobs
```python
# Production klines extraction
python -m jobs.extract_klines_production --period 15m --symbols BTCUSDT,ETHUSDT

# Gap filling
python -m jobs.extract_klines_gap_filler --period 1h --symbols BTCUSDT

# Funding rates extraction
python -m jobs.extract_funding --symbols BTCUSDT,ETHUSDT

# Trades extraction
python -m jobs.extract_trades --symbols BTCUSDT
```

### Data Models
```python
from models.kline import KlineModel
from models.funding_rate import FundingRateModel
from models.trade import TradeModel

# Create kline model
kline = KlineModel(
    symbol="BTCUSDT",
    interval="15m",
    open_time=datetime.now(),
    open_price=Decimal("50000.00"),
    high_price=Decimal("50100.00"),
    low_price=Decimal("49900.00"),
    close_price=Decimal("50050.00"),
    volume=Decimal("100.5")
)

# Create funding rate model
funding_rate = FundingRateModel(
    symbol="BTCUSDT",
    funding_rate=Decimal("0.0001"),
    funding_time=datetime.now()
)
```

### Database Adapters
```python
from db import get_adapter

# Get MongoDB adapter
mongodb_adapter = get_adapter("mongodb", "mongodb://localhost:27017")

# Get MySQL adapter
mysql_adapter = get_adapter("mysql", "mysql://user:pass@localhost:3306/db")

# Use adapter
with mongodb_adapter:
    mongodb_adapter.insert_klines(klines_data)
```

## ğŸš¨ Troubleshooting

### Common Issues

#### Database Connection Issues
```bash
# Check database connectivity
python -c "from db import get_adapter; print('Database adapter available')"

# Test MongoDB connection
python -c "import pymongo; print('MongoDB library available')"

# Test MySQL connection
python -c "import pymysql; print('MySQL library available')"

# Check environment variables
env | grep -E "(MONGODB|MYSQL|POSTGRESQL|DB)"
```

#### API Connection Issues
```bash
# Check Binance API connectivity
curl -s https://api.binance.com/api/v3/ping

# Test API rate limits
curl -s https://api.binance.com/api/v3/exchangeInfo | head -20

# Check environment variables
env | grep -E "(BINANCE|API)"
```

#### Kubernetes Issues
```bash
# Check pod status
kubectl --kubeconfig=k8s/kubeconfig.yaml get pods -n petrosa-apps -l app=binance-data-extractor

# View logs
kubectl --kubeconfig=k8s/kubeconfig.yaml logs -n petrosa-apps -l app=binance-data-extractor

# Check cronjob status
kubectl --kubeconfig=k8s/kubeconfig.yaml get cronjobs -n petrosa-apps
```

#### Performance Issues
- Check memory usage: `docker stats` or Kubernetes metrics
- Monitor database connection pool
- Verify API rate limits
- Check extraction job logs

## ğŸ¯ Next Steps

### Immediate Actions
1. **Test the Service**: Run the test suite and verify functionality
2. **Deploy to Development**: Deploy to development environment
3. **Monitor Performance**: Set up monitoring and alerting
4. **Documentation**: Complete API documentation

### Future Enhancements
1. **Additional Data Types**: Support for more Binance data types
2. **Real-time Streaming**: Integration with WebSocket client
3. **Advanced Analytics**: Built-in data analysis capabilities
4. **Multi-Exchange Support**: Support for other exchanges
5. **Data Compression**: Efficient storage and retrieval

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Support

For support and questions:
- **Issues**: [GitHub Issues](https://github.com/petrosa/petrosa-binance-data-extractor/issues)
- **Documentation**: [Project Wiki](https://github.com/petrosa/petrosa-binance-data-extractor/wiki)
- **Discussions**: [GitHub Discussions](https://github.com/petrosa/petrosa-binance-data-extractor/discussions)

---

**ğŸš€ Production-ready historical data extraction system for Binance cryptocurrency exchange**
